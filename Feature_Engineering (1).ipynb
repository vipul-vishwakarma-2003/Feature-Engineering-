{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering\n",
        "\n",
        "---\n",
        "\n",
        "1.  What is a parameter?\n",
        "  - Parameters are actually a variables this means they are the placeholders they holds the actual value in them which we need further.\n",
        "\n",
        "2.  What is correlation? What does negative correlation mean?\n",
        "  - correlation describe the relationship between the variables. It can be described as either strong or weak, and as either positive or negative.\n",
        "  - A negative correlation means the two variables moves in the opposite direction, in other words when A increases and B descreses negative correlation occurs.\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "  - Machine learning is all about learning the pattern of the data given. Main components of machine learnings are : Data collection and Ingestion, Data preprocessing and Transformation, Feature Engineering, Model training and Model testing.\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "  - Loss is a numerical metric that describes how wrong a model's predictions are. Loss measures the distance between the model's predictions and the actual labels. The goal of training a model is to minimize the loss, reducing it to its lowest possible value.\n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        "  - Continous variables are the numerical data the data which remains between - infinite to + infinite or it can be descrite in nature.\n",
        "  - catagorical variables are the data which stores in the string form, the data where we cannot perform the mathmatics and connot give them a ranking.\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "  - We can handle the categorical variable by using the statistics we can fill the missing data by using the mode function. Common techniques to handle the categorical varibles are : One Hot Encoding, Label Encoding, Effect Encoding, etc.\n",
        "\n",
        "7.  What do you mean by training and testing a dataset?\n",
        "  - Training simply means we take some amount of data to train our model to perform further by using machine learnings techniques, and we use remaining data to test our trained models are they running properly or not?\n",
        "  - In industry we use 70% of data to train the model and remaining 30% data to test the model, Or we can use 80 : 20 ratio to train and test the model.\n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        "  - The sklearn. preprocessing package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators.\n",
        "\n",
        "9. What is a Test set?\n",
        "  - Test set are the amount of data which use to test the model which we have trained so that our model can perform for the varius type data models.\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        " How do you approach a Machine Learning problem?\n",
        "  - We use mostly the 70 : 30 ratio to split the data for model fitting, but it depends on us what ratio we want to do model fitting.\n",
        "  - Data Collection ; Data Preparation ; Choose a Model ; Train the Model ; Evaluate the Model ; Parameter Tuning ; Make Predictions.\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "  - Before fitting any model, it is often important to conduct an exploratory data analysis (EDA) in order to check assumptions, inspect the data for anomalies (such as missing, duplicated, or mis-coded data), and inform feature selection/transformation.\n",
        "\n",
        "12. What is correlation?\n",
        "  - correlation describe the relationship between the variables. It can be described as either strong or weak, and as either positive or negative.\n",
        "\n",
        "13. What does negative correlation mean?\n",
        "  - A negative correlation means the two variables moves in the opposite direction, in other words when A increases and B descreses negative correlation occurs.\n",
        "\n",
        "14. How can you find correlation between variables in Python?\n",
        "  - In Python, you can determine the correlation between variables using various methods such as correlation matrix, Heatmap Visualization, Scatter Plots, Spearman and Kendall Correlation. above methods helps to understand correlation between the variables in dataset.\n",
        "\n",
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "  - Causation means action A causes outcome B. On the other hand, correlation is simply a relationship where action A relates to action Bâ€”but one event doesn't necessarily cause the other event to happen.\n",
        "\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "  - Optimizers are algorithms used to find the optimal set of parameters for a model during the training process. These algorithms adjust the weights and biases in the model iteratively until they converge on a minimum loss value.\n",
        "  - Gradient Descent can be considered the popular kid among the class of optimizers in deep learning. This optimization algorithm uses calculus to consistently modify the values and achieve the local minimum.\n",
        "  - SciPy optimization (scipy.optimize)\n",
        "\n",
        "17. What is sklearn.linear_model ?\n",
        "  - linear_model is a class of the sklearn module if contain different functions for performing machine learning with linear models. The term linear model implies that the model is specified as a linear combination of features.\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "  - The fit() method adjusts the model parameters based on the input data ( X ) and the target values ( y ). The models tries to minimize the error between it's prediction and actual target.\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "  - model. predict() is used to generate predictions from the trained model based on new input data. It does not require true labels and does not compute any metrics.\n",
        "\n",
        "20. What are continuous and categorical variables?\n",
        "  - Continous variables are the numerical data the data which remains between - infinite to + infinite or it can be descrite in nature.\n",
        "  - catagorical variables are the data which stores in the string form, the data where we cannot perform the mathmatics and connot give them a ranking.\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "  - Feature scaling in Machine Learning is a method used to normalize the range of independent variables or features of data.\n",
        "  - Feature scaling is a vital pre processing step in machine learning that involves transforming numerical features to a common scale. It plays a major role in ensuring accurate and efficient model training and performance.\n",
        "\n",
        "22. How do we perform scaling in Python?\n",
        "  - To perform feature scaling in Python, you can use the preprocessing module in sklearn. You can use the MinMaxScaler and StandardScaler to perform normalization and standardization.\n",
        "\n",
        "23. What is sklearn.preprocessing?\n",
        "  - The sklearn. preprocessing package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators.\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "  - We use mostly the 70 : 30 ratio to split the data for model fitting, but it depends on us what ratio we want to do model fitting.\n",
        "\n",
        "25. Explain data encoding?\n",
        "  - Encoding is the process of converting the data or a given sequence of characters, symbols, alphabets etc., into a specified format, for the secured transmission of data.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ton490-dOGd_"
      }
    }
  ]
}